import os
import shutil
import time
from fastapi import FastAPI, File, UploadFile, HTTPException, Query
from fastapi.responses import FileResponse, JSONResponse
from dotenv import load_dotenv
from pydantic import BaseModel
from langchain_community.chat_models import ChatOpenAI
from langchain_community.embeddings import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain.chains import ConversationalRetrievalChain

# âœ… í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    raise HTTPException(status_code=500, detail="âŒ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

# âœ… FastAPI ì„¤ì •
app = FastAPI(
    title="DisToPia API",
    description="DTP ì„¸ê³„ê´€ API (DB + AI + RAG + íŒŒì¼ ê´€ë¦¬)",
    version="4.0"
)

UPLOAD_DIR = "uploads"
os.makedirs(UPLOAD_DIR, exist_ok=True)

# =============================================================================
# âœ… ê¸°ë³¸ ê²½ë¡œ (404 ì˜¤ë¥˜ í•´ê²°)
# =============================================================================
@app.get("/")
def root():
    return {"message": "DisToPia API is running! ğŸš€"}

# =============================================================================
# âœ… ChromaDB ë²¡í„° ê²€ìƒ‰ (RAG)
# =============================================================================
def get_chroma_client():
    embeddings = OpenAIEmbeddings(model="text-embedding-ada-002", openai_api_key=OPENAI_API_KEY)
    vectordb = Chroma(collection_name="distopia_collection", persist_directory="chroma_db", embedding_function=embeddings)
    return vectordb

# =============================================================================
# âœ… íŒŒì¼ ì—…ë¡œë“œ & ë‹¤ìš´ë¡œë“œ API
# =============================================================================
@app.post("/upload/")
async def upload_file(file: UploadFile = File(...)):
    ext = file.filename.split('.')[-1].lower()
    allowed_extensions = ["zip", "png", "jpg", "jpeg", "mp4", "avi"]
    if ext not in allowed_extensions:
        raise HTTPException(status_code=400, detail="ì§€ì›ë˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤.")

    file_path = os.path.join(UPLOAD_DIR, file.filename)
    # ë™ì¼í•œ íŒŒì¼ëª…ì´ ì¡´ì¬í•˜ë©´ íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ ë¶™ì—¬ì„œ ê³ ìœ í™”
    if os.path.exists(file_path):
        base, extension = os.path.splitext(file.filename)
        file.filename = f"{base}_{int(time.time())}{extension}"
        file_path = os.path.join(UPLOAD_DIR, file.filename)

    with open(file_path, "wb") as buffer:
        shutil.copyfileobj(file.file, buffer)
    
    return {"filename": file.filename, "message": "âœ… ì—…ë¡œë“œ ì™„ë£Œ"}

@app.get("/files/")
def list_files():
    try:
        files = os.listdir(UPLOAD_DIR)
        return {"files": files}
    except FileNotFoundError:
        raise HTTPException(status_code=404, detail="âŒ ì—…ë¡œë“œ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤.")

@app.get("/download/{filename}/")
def download_file(filename: str):
    file_path = os.path.join(UPLOAD_DIR, filename)
    if os.path.exists(file_path):
        return FileResponse(file_path, filename=filename)
    raise HTTPException(status_code=404, detail="âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# =============================================================================
# âœ… Pydantic ëª¨ë¸ (Chat ìš”ì²­)
# =============================================================================
class ChatRequest(BaseModel):
    question: str

# =============================================================================
# âœ… AI ê¸°ë°˜ ëŒ€í™” (GPT-4 + LangChain)
# =============================================================================
@app.post("/chat/")
def chat_with_gpt(request: ChatRequest):
    vectordb = get_chroma_client()
    rag_chain = ConversationalRetrievalChain.from_llm(
        ChatOpenAI(model_name="gpt-4", openai_api_key=OPENAI_API_KEY),
        vectordb.as_retriever()
    )
    result = rag_chain.run({"question": request.question})
    return {"response": result}

# =============================================================================
# âœ… DB ê²€ìƒ‰ API
# =============================================================================
@app.get("/search/")
def search_data(query: str = Query(..., description="ê²€ìƒ‰í•  ì¿¼ë¦¬ ë¬¸ìì—´")):
    vectordb = get_chroma_client()
    search_results = vectordb.similarity_search(query, k=5)
    return {"results": [doc.page_content for doc in search_results]}

# =============================================================================
# âœ… FastAPI ì‹¤í–‰ (Render ë°°í¬ ìµœì í™”)
# =============================================================================
if __name__ == "__main__":
    import uvicorn
    port = int(os.getenv("PORT", 8000))  # Renderì—ì„œ ìë™ ê°ì§€
    uvicorn.run(app, host="0.0.0.0", port=port)
