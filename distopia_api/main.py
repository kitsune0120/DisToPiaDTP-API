import os
import shutil
from fastapi import FastAPI, Depends, File, UploadFile, HTTPException, Query
from fastapi.responses import FileResponse, HTMLResponse, JSONResponse
from sqlalchemy.orm import Session
from dotenv import load_dotenv
from langchain_community.chat_models import ChatOpenAI
from langchain_community.embeddings import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain.chains import ConversationalRetrievalChain

# âœ… í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    raise HTTPException(status_code=500, detail="âŒ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

# âœ… FastAPI ì„¤ì •
app = FastAPI(
    title="DisToPia API",
    description="DTP ì„¸ê³„ê´€ API (DB + AI + RAG + íŒŒì¼ ê´€ë¦¬)",
    version="4.0"
)

UPLOAD_DIR = "uploads"
os.makedirs(UPLOAD_DIR, exist_ok=True)

# =============================================================================
# âœ… ê¸°ë³¸ ê²½ë¡œ (404 ì˜¤ë¥˜ í•´ê²°)
# =============================================================================
@app.get("/")
def root():
    return {"message": "DisToPia API is running! ğŸš€"}

# =============================================================================
# âœ… ChromaDB ë²¡í„° ê²€ìƒ‰ (RAG)
# =============================================================================
def get_chroma_client():
    embeddings = OpenAIEmbeddings(model="text-embedding-ada-002", openai_api_key=OPENAI_API_KEY)
    vectordb = Chroma(collection_name="distopia_collection", persist_directory="chroma_db", embedding_function=embeddings)
    return vectordb

# =============================================================================
# âœ… íŒŒì¼ ì—…ë¡œë“œ & ë‹¤ìš´ë¡œë“œ API
# =============================================================================
@app.post("/upload/")
async def upload_file(file: UploadFile = File(...)):
    ext = file.filename.split('.')[-1]
    allowed_extensions = ["zip", "png", "jpg", "jpeg", "mp4", "avi"]
    if ext not in allowed_extensions:
        raise HTTPException(status_code=400, detail="ì§€ì›ë˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤.")

    file_path = os.path.join(UPLOAD_DIR, file.filename)
    with open(file_path, "wb") as buffer:
        shutil.copyfileobj(file.file, buffer)
    
    return {"filename": file.filename, "message": "âœ… ì—…ë¡œë“œ ì™„ë£Œ"}

@app.get("/files/")
def list_files():
    try:
        files = os.listdir(UPLOAD_DIR)
        return {"files": files}
    except FileNotFoundError:
        return {"error": "âŒ ì—…ë¡œë“œ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤."}

@app.get("/download/{filename}/")
def download_file(filename: str):
    file_path = os.path.join(UPLOAD_DIR, filename)
    if os.path.exists(file_path):
        return FileResponse(file_path, filename=filename)
    return {"error": "âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}

# =============================================================================
# âœ… AI ê¸°ë°˜ ëŒ€í™” (GPT-4 + LangChain)
# =============================================================================
@app.post("/chat/")
def chat_with_gpt(question: str):
    vectordb = get_chroma_client()
    rag_chain = ConversationalRetrievalChain.from_llm(ChatOpenAI(model_name="gpt-4", openai_api_key=OPENAI_API_KEY), vectordb.as_retriever())
    
    result = rag_chain.run({"question": question})
    return {"response": result}

# =============================================================================
# âœ… DB ê²€ìƒ‰ API
# =============================================================================
@app.get("/search/")
def search_data(query: str):
    vectordb = get_chroma_client()
    search_results = vectordb.similarity_search(query, k=5)
    return {"results": [doc.page_content for doc in search_results]}

# =============================================================================
# âœ… FastAPI ì‹¤í–‰ (Render ë°°í¬ ìµœì í™”)
# =============================================================================
if __name__ == "__main__":
    import uvicorn
    port = int(os.getenv("PORT", 8000))  # Renderì—ì„œ ìë™ ê°ì§€
    uvicorn.run(app, host="0.0.0.0", port=port)
